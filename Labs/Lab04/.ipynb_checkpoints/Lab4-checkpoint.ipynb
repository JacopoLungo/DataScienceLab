{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58461942",
   "metadata": {},
   "source": [
    "# Lab #4\n",
    "## KNN design and implementation\n",
    "\n",
    "As you might remember from Lab. 1, the Iris dataset collects the measurements of different Iris flowers, and each data point is associated with a Iris species (Setosa, Versicolor, or Virginica). In this exercise, you will implement your own version of the the K-Nearest Neighbors algorithm, and you will use it to assign a Iris species (i.e. a label) to flowers whose species is unknown.\n",
    "\n",
    "The KNN algorithm is straightforward. Suppose that some measurements (i.e. records) and their relative species are known in advance. Then, whenever we want to label a new flower, we look at the K most similar points (a.k.a. neighbors) and assign a label accordingly. The simplest solution is using a\n",
    "majority voting scheme: if the majority of the neighbors votes for a label, we will go for it. This approach is naive only at first sight: the local similarity assumed by KNN happens to be roughly true. Even though this reasoning does not generalize well1, the KNN provides a valid baseline for your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3547218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e4b5e",
   "metadata": {},
   "source": [
    "**1.** Loading the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd16c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepalLength</th>\n",
       "      <th>sepalWidth</th>\n",
       "      <th>petalLength</th>\n",
       "      <th>petalWidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepalLength  sepalWidth  petalLength  petalWidth           class\n",
       "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
       "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
       "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
       "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
       "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
       "..           ...         ...          ...         ...             ...\n",
       "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
       "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
       "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
       "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
       "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sepalLength','sepalWidth','petalLength','petalWidth','class']\n",
    "df = pd.read_csv(\"iris.data\",names = cols , header = None) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba113c",
   "metadata": {},
   "source": [
    "**2.** Let’s identify a portion of our data for which we will try to guess the species. Randomly select 20% of the records and store the first four columns (i.e. the features representing each flower) into a two-dimensional numpy array of shape N × C, you can call it X_test.\n",
    "\n",
    "For the same records, store the last column (i.e. the one with the species values) into another array, namely y_test. This is the data that will be used to test the accuracy of your KNN implementation and its correct functioning (i.e. the testing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac566b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDf = df.sample(frac = 0.2)\n",
    "X_test = sampleDf.iloc[:,:-1]\n",
    "y_test = sampleDf.iloc[:,-1]\n",
    "#print(X_test)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8376e2",
   "metadata": {},
   "source": [
    "**3.** Store the remaining 80% of the records in the same way. In this case, use the names X_train and y_train for the arrays. This is the data that your model will use as ground-truth knowledge (i.e. the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b920e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[~df.index.isin(X_test.index)].iloc[:,:-1]\n",
    "y_train = df.loc[~df.index.isin(y_test.index)].iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d4d2e",
   "metadata": {},
   "source": [
    "**4.** Focus now on the KNN technique. Starting from the next laboratory, you will use the scikit-learn package. Many of its functionalities\n",
    "are exposed via an object-oriented interface. With this paradigm in mind, implement now the KNN\n",
    "algorithm and expose it as a Python class.\n",
    "\n",
    "**5.** Your implementation must support three different distance definitions:\n",
    "* Euclidean Distance (distance_metric = \"euclidean\")\n",
    "* Cosine Distance (distance_metric = \"cosine\")\n",
    "* Manhattan Distance (distance_metric = \"manhattan\")\n",
    "\n",
    "**6.** Implement the predict method. The function receives as input a numpy array with N rows and C columns, corresponding to N flowers. The method assigns one of the three Iris species to each row using the KNN algorithm, and returns them as a numpy array. For the actual implementation, apply the identify K neighbors using the distance specified by the parameters k and distance passed to the constructor.\n",
    "Then, assign the label using a majority voting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d696220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: p, q are two np.arrays of the same lenght\n",
    "#output: the Euclidean distnace as a float\n",
    "\n",
    "def EuclideanDist(p,q):\n",
    "    if len(p) != len(q):\n",
    "        print('Error: input arrays have different lenghts')\n",
    "    else:\n",
    "        d = p - q\n",
    "        d = np.square(d)\n",
    "        return np.round(math.sqrt(sum(d)), decimals = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5424d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: p, q are two np.arrays of the same lenght\n",
    "#output: the cosine distnace as a float\n",
    "\n",
    "def CosineDist(p,q):\n",
    "    if len(p) != len(q):\n",
    "        print('Error: input arrays have different lenghts')\n",
    "    else:\n",
    "        def cs(p,q):\n",
    "            pSq = [x**2 for x in p]\n",
    "            qSq = [x**2 for x in q]\n",
    "            numToBeSummed = [x*y for x,y in zip(p,q)] \n",
    "            return sum(numToBeSummed)/(math.sqrt(sum(pSq))*math.sqrt(sum(qSq)))\n",
    "            \n",
    "        return np.round(1 - abs(cs(p,q)), decimals = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c84c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: p, q are two np.arrays of the same lenght\n",
    "#output: the Manhattan distnace as a float\n",
    "\n",
    "def ManhattanDist(p,q):\n",
    "    if len(p) != len(q):\n",
    "        print('Error: input arrays have different lenghts')\n",
    "    else:\n",
    "        return sum(abs(p-q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed874fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    #distance_metric can be \"euclidean\" or \"cosine\" or \"manhattan\"\n",
    "    def __init__(self, k, distance_metric=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):    \n",
    "        \"\"\"\n",
    "        Store the 'prior knowledge' of you model that will be used\n",
    "        to predict new labels.\n",
    "        :param X : input data points, ndarray, shape = (R,C).\n",
    "        :param y : input labels, ndarray, shape = (R,).\n",
    "        \"\"\"\n",
    "        #self.model = pd.concat([X_test, y_test],axis = 1)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Run the KNN classification on X.\n",
    "        :param X: input data points, ndarray, shape = (N,C).\n",
    "        :return: labels : ndarray, shape = (N,).\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        #Implement the function to apply to each row\n",
    "        def singlePrediction(row):\n",
    "            distType={'euclidean':'Euclidean distance',\n",
    "                      'cosine':'Cosine distance',\n",
    "                     'manhattan':'Manhattan distance'}\n",
    "            sampleRow = row\n",
    "            rowOutputDf = pd.DataFrame()\n",
    "            if self.distance_metric == \"euclidean\":\n",
    "                rowOutputDf['Euclidean distance'] = self.X_train.apply(lambda row : EuclideanDist(row,sampleRow),axis = 1)\n",
    "            \n",
    "            elif self.distance_metric == \"cosine\":\n",
    "                rowOutputDf['Cosine distance'] = self.X_train.apply(lambda row : CosineDist(row,sampleRow),axis = 1)\n",
    "                \n",
    "            elif self.distance_metric == \"manhattan\":\n",
    "                rowOutputDf['Manhattan distance'] = self.X_train.apply(lambda row : ManhattanDist(row,sampleRow),axis = 1)\n",
    "                \n",
    "            #print(rowOutputDf['EucliDist'])\n",
    "            rowOutputDf['label'] = self.y_train\n",
    "            #print(rowOutputDf['label'])\n",
    "            neighbors = rowOutputDf.nsmallest(self.k+1, distType[self.distance_metric]).loc[:,'label']\n",
    "            \n",
    "            #return the most frequent element in a list\n",
    "            prediction = max(set(neighbors.tolist()), key=neighbors.tolist().count)\n",
    "            #print(prediction)\n",
    "            return prediction\n",
    "    \n",
    "        self.y = pd.DataFrame()\n",
    "        self.y['label'] = self.X.apply(lambda row : singlePrediction(row), axis = 1)\n",
    "        return self.y['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d4b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestNeighbors(5,distance_metric=\"manhattan\")\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c86eac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "comp = y_pred == y_test\n",
    "accuracy = comp.sum()/len(comp)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9954a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dslab]",
   "language": "python",
   "name": "conda-env-dslab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
